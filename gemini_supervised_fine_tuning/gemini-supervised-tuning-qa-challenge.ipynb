{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDcI0SYySZiu"
   },
   "source": [
    "# [CEPF L300]: Tune Gemini Model by using Supervised Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2D59iF36T62k"
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fEBa5FbT-dc"
   },
   "source": [
    "### Install Vertex AI SDK and other required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0M04I5j3_KY5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade --user --quiet google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MyKgURhIUnAM"
   },
   "source": [
    "## Set Project and Location\n",
    "\n",
    "First, you have to set your project_id, location, and bucket_name. You can also use an existing bucket within the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4acO9tVcU1Ey",
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_id_output = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "PROJECT_ID = project_id_output[0]\n",
    "REGION = !gcloud compute project-info describe --format=\"value[](commonInstanceMetadata.items.google-compute-default-region)\"\n",
    "LOCATION = REGION[0]\n",
    "\n",
    "BUCKET_NAME = f\"{PROJECT_ID}-model-dataset\"\n",
    "BUCKET_URI = f\"gs://{BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkBZ-e85UeiI"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "jsnIinC4UfZq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import (\n",
    "    GenerativeModel,\n",
    "    Part,\n",
    "    HarmCategory,\n",
    "    HarmBlockThreshold,\n",
    "    GenerationConfig,\n",
    ")\n",
    "from vertexai.preview.tuning import sft\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION) ###\n",
    "\n",
    "from typing import Union\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbaPSIO4_iur"
   },
   "source": [
    "## Generate the training and validation dataset files\n",
    "\n",
    "To create a tuning job, you use a Q&A with a context dataset in JSON format.\n",
    "\n",
    "Supervised fine-tuning offers a solution, as it allows focused adaptation of foundation models to new tasks. You can create a supervised text model tuning job using the Google Cloud console, API, or the Vertex AI SDK for Python. For more information, refer to the [documentation page](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini-use-supervised-tuning),\n",
    "\n",
    "But how do you ensure your data is primed for success with supervised fine-tuning? Here are the critical areas to focus on:\n",
    "\n",
    "- **Domain Alignment:** Supervised fine-tuning thrives on smaller datasets, but they must be highly relevant to your downstream task. Look for data that closely mirrors the domain you will encounter in real-world use cases.\n",
    "- **Labeling Accuracy:** Noisy labels sabotage even the best technique. Prioritize accuracy in your annotations and labeling.\n",
    "- **Noise Reduction:** Outliers, inconsistencies, or irrelevant examples hurt model adaptation. Implement preprocessing, such as removing duplicates, fixing typos, and verifying that data conforms to your task's expectations.\n",
    "- **Distribution:** A diverse range of examples helps your model generalize better within the confines of your target task. Refrain from overloading the process with excessive variance that strays from your core domain.\n",
    "- **Balanced Classes:** For classification tasks, try to keep a reasonable balance between different classes to avoid the model learning biases towards a specific class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivFjWO5M-Z8H"
   },
   "source": [
    "### Fetching data from BigQuery\n",
    "\n",
    "Your model tuning dataset must be in a JSONL format where each line contains a single training example. You must make sure that you include instructions.\n",
    "\n",
    "You will use the [StackOverflow dataset](https://cloud.google.com/blog/topics/public-datasets/google-bigquery-public-datasets-now-include-stack-overflow-q-a) on BigQuery Public Datasets, limiting to questions with the `python` tag, and accepted answers for answers since 2020-01-01.\n",
    "\n",
    "You use a helper function to read the data from BigQuery and create a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "2JIlL-aVbNPg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_bq_query(sql: str) -> Union[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Run a BigQuery query and return the job ID or result as a DataFrame\n",
    "    Args:\n",
    "        sql: SQL query, as a string, to execute in BigQuery\n",
    "    Returns:\n",
    "        df: DataFrame of results from query,  or error, if any\n",
    "    \"\"\"\n",
    "\n",
    "    bq_client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "    # Try dry run before executing query to catch any errors\n",
    "    job_config = bigquery.QueryJobConfig(dry_run=True, use_query_cache=False)\n",
    "    bq_client.query(sql, job_config=job_config)\n",
    "\n",
    "    # If dry run succeeds without errors, proceed to run query\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    client_result = bq_client.query(sql, job_config=job_config)\n",
    "\n",
    "    job_id = client_result.job_id\n",
    "\n",
    "    # Wait for query/job to finish running. then get & return DataFrame\n",
    "    df = client_result.result().to_arrow().to_pandas()\n",
    "    print(f\"Finished job_id: {job_id}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11WLzqp-b59c"
   },
   "source": [
    "Next you write the query. Limit your example to 550.\n",
    "\n",
    "**TODO:** Update the query below to limit the results to 550."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "gLC_elwzb3ZF",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished job_id: 6e9afed5-ba0a-4937-ab5c-19c2d7be8bcc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>output_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Django user authentication with case insensiti...</td>\n",
       "      <td>&lt;p&gt;You should make a custom authentication bac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Selenium using WebDriverWait WebElement still ...</td>\n",
       "      <td>&lt;p&gt;I checked the HTML DOM and I don't see any ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Want to create a tab delimited file with auton...</td>\n",
       "      <td>&lt;p&gt;Use &lt;code&gt;zip&lt;/code&gt; to easily pair the dof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Getting individual Pandas dataframes instead o...</td>\n",
       "      <td>&lt;p&gt;A simpler solution would be to extract all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TypeError using pprint on Counter() objects th...</td>\n",
       "      <td>&lt;p&gt;&lt;code&gt;pprint&lt;/code&gt; is not at blame here. W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  \\\n",
       "0  Django user authentication with case insensiti...   \n",
       "1  Selenium using WebDriverWait WebElement still ...   \n",
       "2  Want to create a tab delimited file with auton...   \n",
       "3  Getting individual Pandas dataframes instead o...   \n",
       "4  TypeError using pprint on Counter() objects th...   \n",
       "\n",
       "                                         output_text  \n",
       "0  <p>You should make a custom authentication bac...  \n",
       "1  <p>I checked the HTML DOM and I don't see any ...  \n",
       "2  <p>Use <code>zip</code> to easily pair the dof...  \n",
       "3  <p>A simpler solution would be to extract all ...  \n",
       "4  <p><code>pprint</code> is not at blame here. W...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_overflow_df = run_bq_query(\n",
    "    \"\"\"SELECT\n",
    "           CONCAT(q.title, q.body) AS input_text,\n",
    "           a.body AS output_text\n",
    "       FROM `bigquery-public-data.stackoverflow.posts_questions` q\n",
    "       JOIN `bigquery-public-data.stackoverflow.posts_answers` a\n",
    "         ON q.accepted_answer_id = a.id\n",
    "       WHERE q.accepted_answer_id IS NOT NULL\n",
    "         AND REGEXP_CONTAINS(q.tags, \"python\")\n",
    "         AND a.creation_date >= \"2020-01-01\"\n",
    "       LIMIT 550\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "stack_overflow_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b404hW8jcRDQ"
   },
   "source": [
    "There should be 550 questions and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "mUg-lF61cUVI",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550\n"
     ]
    }
   ],
   "source": [
    "print(len(stack_overflow_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHda8BzbmRMC"
   },
   "source": [
    "### Adding instructions\n",
    "Finetuning language models on a collection of datasets phrased as instructions improve model performance and generalization to unseen tasks [(Google, 2022)](https://arxiv.org/pdf/2210.11416.pdf).\n",
    "\n",
    "An instruction refers to a specific directive or guideline that conveys a task or action to be executed. These instructions can be expressed in various forms, such as step-by-step procedures, commands, or rules. When you don't use the instructions, it's only a question and answer. The instruction tells the large language model what to do. You want them to answer the question. You have to give a hint about the task you want to perform. Extend the dataset with an instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "XIy7BjKWmu5j",
    "tags": []
   },
   "outputs": [],
   "source": [
    "INSTRUCTION_TEMPLATE = f\"\"\"\\\n",
    "You are a helpful Python developer \\\n",
    "You are good at answering Stackoverflow questions \\\n",
    "Your mission is to provide developers with helpful answers that work\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tM_f1b3n4TK"
   },
   "source": [
    "Create a new column for the `INSTRUCTION_TEMPLATE`. Use a new column and do not overwrite the existing one because you might want to use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "UJpAJG8uoE7F",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>output_text</th>\n",
       "      <th>input_text_instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Django user authentication with case insensiti...</td>\n",
       "      <td>&lt;p&gt;You should make a custom authentication bac...</td>\n",
       "      <td>You are a helpful Python developer You are goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Selenium using WebDriverWait WebElement still ...</td>\n",
       "      <td>&lt;p&gt;I checked the HTML DOM and I don't see any ...</td>\n",
       "      <td>You are a helpful Python developer You are goo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  \\\n",
       "0  Django user authentication with case insensiti...   \n",
       "1  Selenium using WebDriverWait WebElement still ...   \n",
       "\n",
       "                                         output_text  \\\n",
       "0  <p>You should make a custom authentication bac...   \n",
       "1  <p>I checked the HTML DOM and I don't see any ...   \n",
       "\n",
       "                                 input_text_instruct  \n",
       "0  You are a helpful Python developer You are goo...  \n",
       "1  You are a helpful Python developer You are goo...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_overflow_df[\"input_text_instruct\"] = INSTRUCTION_TEMPLATE\n",
    "\n",
    "stack_overflow_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNMMxaB2cZvY"
   },
   "source": [
    "**TODO:**\n",
    "Next, you split the data into training and evaluation. For Extractive Q&A tasks, it's advised 500+ training examples. In this case, you use 440 to generate a tuning job that runs faster. \n",
    "\n",
    "20% of your dataset is used for testing. The `random_state` controls the shuffling applied to the data before applying the split. Pass an int for reproducible output across multiple function calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "qdrweRsscfgU",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records in training dataset: 440\n",
      "Total number of records in validation dataset: 110\n"
     ]
    }
   ],
   "source": [
    "# TODO: Update the test_size to select 20% of data for evaluation\n",
    "train, evaluation = train_test_split(stack_overflow_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Warning - Don't change the following print statements. It is used for score tracking. \n",
    "# Please don't forget to save this notebook script.\n",
    "print('Total number of records in training dataset:',len(train))\n",
    "print('Total number of records in validation dataset:',len(evaluation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to the **Task 4. Generate the training and validation dataset files** section of the lab instructions and click  **Check my progress** to verify the __Split the dataset for training and evaluation__ objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_MuRRGmfLni"
   },
   "source": [
    "### Generate the JSONL files\n",
    "\n",
    "Prepare your training data in a JSONL (JSON Lines) file and store it in a Google Cloud Storage (GCS) bucket. This format ensures efficient processing. Each line of the JSONL file must represent a single data instance and follow a well-defined schema:\n",
    "\n",
    "`{ \"systemInstruction\": {\"role\": \"system\", \"parts\": [{\"text\": \"instructions\"}]},\n",
    "  \"contents\": [{\"role\": \"user\", \"parts\": [{\"text\": \"question\"}]},{\"role\": \"model\", \"parts\": [{\"text\": \"answering\"}]}]}`\n",
    "\n",
    "This is how it maps to the Pandas df columns:\n",
    "\n",
    "*   `instructions -> input_text_instruct`\n",
    "*   `question -> input_text`\n",
    "*   `answer -> output_text`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "fgPXoXOlc0vI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuning_data_filename = f\"tune_data_stack_overflow_qa.jsonl\"\n",
    "validation_data_filename = f\"validation_data_stack_overflow_qa.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "9-oHmx0wfElN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_messages(row):\n",
    "    \"\"\"Formats a single row into the desired JSONL structure\"\"\"\n",
    "    return {\n",
    "      \"systemInstruction\": {\n",
    "        \"role\": \"system\",\n",
    "        \"parts\": [\n",
    "          {\n",
    "            \"text\": row[\"input_text_instruct\"]\n",
    "          }\n",
    "        ]\n",
    "      },\n",
    "      \"contents\": [\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"parts\": [\n",
    "            {\n",
    "              \"text\": row[\"input_text\"]\n",
    "            }\n",
    "          ]\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"model\",\n",
    "          \"parts\": [\n",
    "            {\n",
    "              \"text\": row[\"output_text\"]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "8mBwn2jJEkYl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply formatting function to each row, then convert to JSON Lines format\n",
    "tuning_data = train.apply(format_messages, axis=1).to_json(orient=\"records\", lines=True)\n",
    "\n",
    "# Save the result to a JSONL file\n",
    "with open(tuning_data_filename, \"w\") as f:\n",
    "    f.write(tuning_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yz9IbouGftaZ"
   },
   "source": [
    "Next, check if the number of rows match with your Pandas df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "w4JfgAijikHp",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the JSONL file: 440\n"
     ]
    }
   ],
   "source": [
    "with open(tuning_data_filename, \"r\") as f:\n",
    "    num_rows = sum(1 for line in f)\n",
    "\n",
    "print(\"Number of rows in the JSONL file:\", num_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42u53mHQVZk3"
   },
   "source": [
    "Do the same for the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "nBc6ufE0h2zL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply formatting function to each row, then convert to JSON Lines format\n",
    "validation_data = evaluation.apply(format_messages, axis=1).to_json(\n",
    "    orient=\"records\", lines=True\n",
    ")\n",
    "\n",
    "# Save the result to a JSONL file\n",
    "with open(validation_data_filename, \"w\") as f:\n",
    "    f.write(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sYGr7h_2ahqb"
   },
   "source": [
    "Next, copy the JSONL files into the Google Cloud Storage bucket you specified or created at the beginning of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "eq0MYC6nxhKy",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://tune_data_stack_overflow_qa.jsonl [Content-Type=application/octet-stream]...\n",
      "Copying file://validation_data_stack_overflow_qa.jsonl [Content-Type=application/octet-stream]...\n",
      "/ [2 files][  1.6 MiB/  1.6 MiB]                                                \n",
      "Operation completed over 2 objects/1.6 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp $tuning_data_filename $validation_data_filename $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cBq0NMIxa2iD"
   },
   "source": [
    "Check if the files are in the bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "cVel0g6pkOiA",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     22919  2025-12-24T08:47:47Z  gs://qwiklabs-gcp-01-1ff54daeef9f-model-dataset/gemini-supervised-tuning-qa-challenge.ipynb#1766566067749390  metageneration=1\n",
      "   1400039  2025-12-24T09:08:44Z  gs://qwiklabs-gcp-01-1ff54daeef9f-model-dataset/tune_data_stack_overflow_qa.jsonl#1766567324788772  metageneration=1\n",
      "    327002  2025-12-24T09:08:44Z  gs://qwiklabs-gcp-01-1ff54daeef9f-model-dataset/validation_data_stack_overflow_qa.jsonl#1766567324917922  metageneration=1\n",
      "TOTAL: 3 objects, 1749960 bytes (1.67 MiB)\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls -al $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hsc0xhNGa7ZQ"
   },
   "source": [
    "Create two variables for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "tXzEZFjtkTWJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "TUNING_DATA_URI = f\"{BUCKET_URI}/{tuning_data_filename}\"\n",
    "VALIDATION_DATA_URI = f\"{BUCKET_URI}/{validation_data_filename}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to the **Task 4. Generate the training and validation dataset files** section of the lab instructions and click  **Check my progress** to verify the __Store the training and validation files in Cloud Storage__ objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAOu-xJnA54y"
   },
   "source": [
    "## Start a supervised tuning job using Gemini\n",
    "It's time to start your tuning job. Use the `gemini-2.0-flash-001` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "SodJv2vWicfu",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/vertexai/generative_models/_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n"
     ]
    }
   ],
   "source": [
    "foundation_model = GenerativeModel(\"gemini-2.0-flash-001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Create a supervised fine-tuning job with following parameters: \n",
    "\n",
    "* **Tuned model display name:** `StackOverflow Q&A Supervised Tuning Job`\n",
    "* **Source model:** gemini-2.0-flash-001\n",
    "* **Training dataset:** tune_data_stack_overflow_qa.jsonl\n",
    "* **Validation dataset:** validation_data_stack_overflow_qa.jsonl\n",
    "* **Epochs:** 3\n",
    "* **Learning Rate Multiplier:** 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "6e7zBH5foZbC",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating SupervisedTuningJob\n",
      "SupervisedTuningJob created. Resource name: projects/269318095290/locations/us-west4/tuningJobs/3881765328723640320\n",
      "To use this SupervisedTuningJob in another session:\n",
      "tuning_job = sft.SupervisedTuningJob('projects/269318095290/locations/us-west4/tuningJobs/3881765328723640320')\n",
      "View Tuning Job:\n",
      "https://console.cloud.google.com/vertex-ai/generative/language/locations/us-west4/tuning/tuningJob/3881765328723640320?project=269318095290\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-e4936764-5bee-4e22-87fd-86a08c52b01e\" href=\"#view-view-vertex-resource-e4936764-5bee-4e22-87fd-86a08c52b01e\">\n",
       "          <span class=\"material-icons view-vertex-icon\">tune</span>\n",
       "          <span>View Tuning Job</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-e4936764-5bee-4e22-87fd-86a08c52b01e');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/generative/language/locations/us-west4/tuning/tuningJob/3881765328723640320?project=269318095290');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/generative/language/locations/us-west4/tuning/tuningJob/3881765328723640320?project=269318095290', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/269318095290/locations/us-west4/tuningJobs/3881765328723640320',\n",
       " 'tunedModelDisplayName': 'StackOverflow Q&A Supervised Tuning Job',\n",
       " 'baseModel': 'gemini-2.0-flash-001',\n",
       " 'supervisedTuningSpec': {'trainingDatasetUri': 'gs://qwiklabs-gcp-01-1ff54daeef9f-model-dataset/tune_data_stack_overflow_qa.jsonl',\n",
       "  'validationDatasetUri': 'gs://qwiklabs-gcp-01-1ff54daeef9f-model-dataset/validation_data_stack_overflow_qa.jsonl',\n",
       "  'hyperParameters': {'epochCount': '3', 'learningRateMultiplier': 1.0}},\n",
       " 'state': 'JOB_STATE_PENDING',\n",
       " 'createTime': '2025-12-24T09:17:29.956185Z',\n",
       " 'updateTime': '2025-12-24T09:17:29.956185Z'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#sft_tuning_job = [ TODO - Insert your code ]\n",
    "\n",
    "sft_tuning_job = sft.train(\n",
    "    source_model=foundation_model,\n",
    "    # 1.5 and 2.0 models use the same JSONL format\n",
    "    train_dataset=TUNING_DATA_URI,\n",
    "    validation_dataset=VALIDATION_DATA_URI,\n",
    "    tuned_model_display_name=\"StackOverflow Q&A Supervised Tuning Job\",\n",
    "    epochs=3,\n",
    "    learning_rate_multiplier=1.0,\n",
    ")\n",
    "\n",
    "\n",
    "# Get the tuning job info.\n",
    "sft_tuning_job.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LSm5Ns5gjx-"
   },
   "source": [
    "Go to the **Task 5. Start a supervised tuning job using Gemini** section of the lab and click  **Check my progress** to verify the __Start a supervised tuning job using Gemini__ objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KgukIEFPlVdD"
   },
   "source": [
    "Next, you retrieve the model resource name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q3yiKi-KofGK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the resource name of the tuning job\n",
    "sft_tuning_job_name = sft_tuning_job.resource_name\n",
    "sft_tuning_job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SM1RZVqWKRdg"
   },
   "source": [
    "Tuning takes approximately 100-120 minutes. Wait until the job is finished before you continue after the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uyug1dw4FAgn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Wait for job completion\n",
    "while not sft_tuning_job.refresh().has_ended:\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing the tuning job, go to the **Task 5. Start a supervised tuning job using Gemini** section of the lab and click  **Check my progress** to verify the __Tune Gemini model using supervised fine-tuning__ objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nyDS9G2TTX9p"
   },
   "outputs": [],
   "source": [
    "# tuned model name\n",
    "tuned_model_name = sft_tuning_job.tuned_model_name\n",
    "tuned_model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_s57xpI5o9m0"
   },
   "source": [
    "Use `tuning.TuningJob.list()` to retrieve your tuning jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8QtT3uJ3Jw0N"
   },
   "outputs": [],
   "source": [
    "sft_tuning_job.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KQmyjjcJ9uz"
   },
   "source": [
    "Your model is automatically deployed as a Vertex AI Endpoint and ready for use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X9uQD-Ee_h6h"
   },
   "outputs": [],
   "source": [
    "# tuned model endpoint name\n",
    "tuned_model_endpoint_name = sft_tuning_job.tuned_model_endpoint_name\n",
    "tuned_model_endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRPlb4ZO8ulD"
   },
   "source": [
    "## Test the tuned model with a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OhfU4wTOtH1y"
   },
   "outputs": [],
   "source": [
    "tuned_model = GenerativeModel(tuned_model_endpoint_name)\n",
    "print(tuned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S1q1PT2zJRO9"
   },
   "outputs": [],
   "source": [
    "question = \"How do I store a TensorFlow checkpoint on Google Cloud Storage while training?\"\n",
    "response = tuned_model.generate_content(question)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the response from model in the Cloud Storage bucket \n",
    "from google.cloud import storage\n",
    "\n",
    "with open('tuned_model_qa_response.txt', \"w+\") as output:\n",
    "    image_content = output.write(response.text)\n",
    "    output.close()\n",
    "\n",
    "storage_client = storage.Client()\n",
    "BUCKET_NAME = f\"{PROJECT_ID}-model-dataset\"\n",
    "bucket = storage_client.get_bucket(BUCKET_NAME)\n",
    "blob = bucket.blob('tuned_model_qa_response.txt')\n",
    "blob.upload_from_filename('tuned_model_qa_response.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to the **Task 6. Test the tuned model with a prompt** section of the lab and click  **Check my progress** to verify the __Test the tuned model with a prompt__ objective."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m137",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m137"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
