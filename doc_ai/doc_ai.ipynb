{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59d64844-18a8-4cec-b4af-5768f4efe12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-documentai\n",
      "  Downloading google_cloud_documentai-3.7.0-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.10/site-packages (3.7.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-documentai) (2.28.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-documentai) (2.43.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-documentai) (1.76.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-documentai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-documentai) (6.33.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-documentai) (1.72.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-documentai) (2.32.5)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-documentai) (1.76.0)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-documentai) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-documentai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-documentai) (4.9.1)\n",
      "Requirement already satisfied: typing-extensions~=4.12 in /opt/conda/lib/python3.10/site-packages (from grpcio<2.0.0,>=1.33.2->google-cloud-documentai) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-documentai) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-documentai) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-documentai) (2.6.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-documentai) (2025.11.12)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-documentai) (0.6.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.5.0)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (2.8.0)\n",
      "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (1.7.1)\n",
      "Downloading google_cloud_documentai-3.7.0-py3-none-any.whl (303 kB)\n",
      "Installing collected packages: google-cloud-documentai\n",
      "Successfully installed google-cloud-documentai-3.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-cloud-documentai google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88db462-01ec-4d31-8945-6a22a42ace93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOCUMENT OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c475676-d95f-453b-a301-0ede562760db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ONLINE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcbb3fb5-6523-4905-9e0f-267b64ac6ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File cepf_online_ocr.txt uploaded to qwiklabs-gcp-03-25b8e7edf7ec-cepf-documentai.\n"
     ]
    }
   ],
   "source": [
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import documentai\n",
    "from google.cloud import storage\n",
    "\n",
    "def online_process_document(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    processor_id: str,\n",
    "    file_path: str,\n",
    "    mime_type: str,\n",
    ") -> documentai.Document:\n",
    "    \"\"\"\n",
    "    Processes a document using the Document AI online processing API.\n",
    "    \"\"\"\n",
    "    # Instantiates a client\n",
    "    docai_client = documentai.DocumentProcessorServiceClient(\n",
    "        client_options=ClientOptions(\n",
    "            api_endpoint=f\"{location}-documentai.googleapis.com\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # The full resource name of the processor\n",
    "    resource_name = docai_client.processor_path(project_id, location, processor_id)\n",
    "\n",
    "    # Read the file into memory\n",
    "    with open(file_path, \"rb\") as image:\n",
    "        image_content = image.read()\n",
    "\n",
    "    # Load Binary Data into Document AI RawDocument Object\n",
    "    raw_document = documentai.RawDocument(\n",
    "        content=image_content, mime_type=mime_type\n",
    "    )\n",
    "\n",
    "    # Configure the process request\n",
    "    request = documentai.ProcessRequest(\n",
    "        name=resource_name,\n",
    "        raw_document=raw_document,\n",
    "    )\n",
    "\n",
    "    # Use the Document AI client to process the sample form\n",
    "    result = docai_client.process_document(request=request)\n",
    "\n",
    "    return result.document\n",
    "\n",
    "\n",
    "def save_text_to_gcs(\n",
    "    bucket_name: str, destination_blob_name: str, text_content: str\n",
    "):\n",
    "    \"\"\"Uploads a string to the bucket.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_string(text_content)\n",
    "\n",
    "    print(f\"File {destination_blob_name} uploaded to {bucket_name}.\")\n",
    "\n",
    "\n",
    "# TODO(developer): Set these variables before running the sample.\n",
    "project_id = \"qwiklabs-gcp-03-25b8e7edf7ec\"\n",
    "location = \"us\"  # e.g., \"us\" or \"eu\"\n",
    "processor_id = \"b617543603c0ec67\"\n",
    "file_path = \"sample-online-ocr.pdf\"\n",
    "mime_type = \"application/pdf\"\n",
    "bucket_name = \"qwiklabs-gcp-03-25b8e7edf7ec-cepf-documentai\"\n",
    "destination_blob_name = \"cepf_online_ocr.txt\"\n",
    "\n",
    "\n",
    "document = online_process_document(\n",
    "    project_id=project_id,\n",
    "    location=location,\n",
    "    processor_id=processor_id,\n",
    "    file_path=file_path,\n",
    "    mime_type=mime_type,\n",
    ")\n",
    "\n",
    "save_text_to_gcs(\n",
    "    bucket_name=bucket_name,\n",
    "    destination_blob_name=destination_blob_name,\n",
    "    text_content=document.text,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb3c2bcd-0fd5-4f90-9723-02c5e0754a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BATCH PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "debc1d3b-6cf2-438a-a693-7a67debc1d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initiate batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "647ad292-5068-4889-89d6-765bdf267da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the batch processing operation to complete...\n",
      "Batch processing complete.\n"
     ]
    }
   ],
   "source": [
    "from google.api_core.client_options import ClientOptions\n",
    "from google.api_core.exceptions import GoogleAPICallError\n",
    "from google.cloud import documentai\n",
    "\n",
    "def batch_process_documents(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    processor_id: str,\n",
    "    gcs_input_uri: str,\n",
    "    gcs_output_bucket: str,\n",
    "    gcs_output_uri_prefix: str,\n",
    "    timeout: int = 400,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Performs batch processing on a document in Cloud Storage.\n",
    "    \"\"\"\n",
    "    # Instantiates a client\n",
    "    docai_client = documentai.DocumentProcessorServiceClient(\n",
    "        client_options=ClientOptions(\n",
    "            api_endpoint=f\"{location}-documentai.googleapis.com\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # The full resource name of the processor\n",
    "    resource_name = docai_client.processor_path(project_id, location, processor_id)\n",
    "\n",
    "    # Configure the input documents\n",
    "    gcs_document = documentai.GcsDocument(\n",
    "        gcs_uri=gcs_input_uri, mime_type=\"application/pdf\"\n",
    "    )\n",
    "    # Load GcsDocument into a GcsDocuments object\n",
    "    gcs_documents = documentai.GcsDocuments(documents=[gcs_document])\n",
    "    input_config = documentai.BatchDocumentsInputConfig(gcs_documents=gcs_documents)\n",
    "\n",
    "    # Configure the output location\n",
    "    gcs_output_config = documentai.DocumentOutputConfig.GcsOutputConfig(\n",
    "        gcs_uri=f\"{gcs_output_bucket}/{gcs_output_uri_prefix}\"\n",
    "    )\n",
    "    output_config = documentai.DocumentOutputConfig(gcs_output_config=gcs_output_config)\n",
    "\n",
    "    # Configure the process request\n",
    "    request = documentai.BatchProcessRequest(\n",
    "        name=resource_name,\n",
    "        input_documents=input_config,\n",
    "        document_output_config=output_config,\n",
    "    )\n",
    "\n",
    "    # Make the batch process request\n",
    "    try:\n",
    "        operation = docai_client.batch_process_documents(request)\n",
    "        # Wait for the operation to complete\n",
    "        print(\"Waiting for the batch processing operation to complete...\")\n",
    "        operation.result(timeout=timeout)\n",
    "        print(\"Batch processing complete.\")\n",
    "\n",
    "    except GoogleAPICallError as e:\n",
    "        print(f\"An error occurred during batch processing: {e}\")\n",
    "\n",
    "\n",
    "# TODO(developer): Set these variables before running the sample.\n",
    "project_id = \"qwiklabs-gcp-03-25b8e7edf7ec\"\n",
    "location = \"us\"  # e.g., \"us\" or \"eu\"\n",
    "processor_id = \"b617543603c0ec67\"\n",
    "# This must be a URI to a file in GCS.\n",
    "gcs_input_uri = \"gs://qwiklabs-gcp-03-25b8e7edf7ec-cepf-documentai/sample-batch-ocr.pdf\"\n",
    "gcs_output_bucket = \"gs://qwiklabs-gcp-03-25b8e7edf7ec-cepf-documentai\"\n",
    "gcs_output_uri_prefix = \"batch-output\" # A folder in your output bucket\n",
    "\n",
    "batch_process_documents(\n",
    "    project_id=project_id,\n",
    "    location=location,\n",
    "    processor_id=processor_id,\n",
    "    gcs_input_uri=gcs_input_uri,\n",
    "    gcs_output_bucket=gcs_output_bucket,\n",
    "    gcs_output_uri_prefix=gcs_output_uri_prefix,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ceb73fb-5de7-42d7-bfab-092b9449d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Consolidate output and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2250fdb-cb85-43d5-a501-eb9b8f356077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing output files...\n",
      "Uploading consolidated text to cepf_batch_ocr.txt...\n",
      "Consolidation and upload complete.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from google.cloud import storage\n",
    "from google.cloud import documentai\n",
    "\n",
    "def get_and_save_batch_results(\n",
    "    gcs_output_bucket: str,\n",
    "    gcs_output_uri_prefix: str,\n",
    "    destination_blob_name: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Parses the output from a Document AI batch process, consolidates the\n",
    "    text, and saves it to a new GCS file.\n",
    "    \"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket_name = gcs_output_bucket.replace(\"gs://\", \"\")\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "    # List all blobs in the specified prefix\n",
    "    blob_list = list(bucket.list_blobs(prefix=gcs_output_uri_prefix))\n",
    "    \n",
    "    full_text = []\n",
    "\n",
    "    print(\"Parsing output files...\")\n",
    "    for blob in blob_list:\n",
    "        # Document AI's batch output consists of multiple JSON files\n",
    "        if \".json\" in blob.name:\n",
    "            # Download the JSON content\n",
    "            json_string = blob.download_as_string()\n",
    "            \n",
    "            # Parse the JSON and extract the text\n",
    "            document = documentai.Document.from_json(json_string, ignore_unknown_fields=True)\n",
    "            \n",
    "            # Add the text to our collection\n",
    "            full_text.append(document.text)\n",
    "\n",
    "    # Concatenate all text and upload to the final destination\n",
    "    print(f\"Uploading consolidated text to {destination_blob_name}...\")\n",
    "    output_blob = bucket.blob(destination_blob_name)\n",
    "    output_blob.upload_from_string(\"\".join(full_text))\n",
    "\n",
    "    print(\"Consolidation and upload complete.\")\n",
    "\n",
    "\n",
    "# TODO(developer): Set these variables before running the sample.\n",
    "# These should match the output settings from the first script.\n",
    "gcs_output_bucket = \"gs://qwiklabs-gcp-03-25b8e7edf7ec-cepf-documentai\"\n",
    "gcs_output_uri_prefix = \"batch-output\"\n",
    "# The final filename for the consolidated text.\n",
    "final_destination_blob_name = \"cepf_batch_ocr.txt\"\n",
    "\n",
    "get_and_save_batch_results(\n",
    "    gcs_output_bucket=gcs_output_bucket,\n",
    "    gcs_output_uri_prefix=gcs_output_uri_prefix,\n",
    "    destination_blob_name=final_destination_blob_name,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f21fb81f-ba68-48ba-9df6-8f9a40fc0c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FORM PARSER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9caf9ab4-47e1-4cc2-b380-68636a091152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8acedd5c-26d9-447a-abf8-479896ff0b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making request to Document AI API...\n",
      "Request complete. Parsing form fields...\n",
      "Found 17 key-value pairs.\n",
      "DataFrame created:\n",
      "                                                 key  \\\n",
      "0  Are you currently taking any medication? (If y...   \n",
      "1                                          _Phone #:   \n",
      "2                                               Zip:   \n",
      "3                                              City:   \n",
      "4                                             State:   \n",
      "\n",
      "                                 value  \n",
      "0  Vyvanse (25mg) daily for attention.  \n",
      "1     walker@cmail.com\\n_Phone #: (906  \n",
      "2                                07082  \n",
      "3                               Towaco  \n",
      "4                                   NJ  \n",
      "Successfully saved output to gs://qwiklabs-gcp-03-25b8e7edf7ec-cepf-documentai/cepf_form_parser.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import documentai\n",
    "from google.cloud import storage\n",
    "from typing import Sequence\n",
    "\n",
    "\n",
    "def process_and_extract_form_data(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    processor_id: str,\n",
    "    gcs_uri: str,\n",
    "    output_bucket: str,\n",
    "    output_filename: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Processes a form document using Document AI, extracts key-value pairs,\n",
    "    and saves the result as a CSV in a Cloud Storage bucket.\n",
    "    \"\"\"\n",
    "    # 1. Instantiate Document AI Client\n",
    "    docai_client = documentai.DocumentProcessorServiceClient(\n",
    "        client_options=ClientOptions(\n",
    "            api_endpoint=f\"{location}-documentai.googleapis.com\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 2. Configure and make the processing request\n",
    "    resource_name = docai_client.processor_path(project_id, location, processor_id)\n",
    "\n",
    "    # Specify that the file is in GCS\n",
    "    gcs_document = documentai.GcsDocument(\n",
    "        gcs_uri=gcs_uri, mime_type=\"application/pdf\"\n",
    "    )\n",
    "\n",
    "    request = documentai.ProcessRequest(\n",
    "        name=resource_name, gcs_document=gcs_document\n",
    "    )\n",
    "\n",
    "    print(\"Making request to Document AI API...\")\n",
    "    result = docai_client.process_document(request=request)\n",
    "    document = result.document\n",
    "    print(\"Request complete. Parsing form fields...\")\n",
    "\n",
    "    # 3. Define a helper function to get text from the document\n",
    "    def get_text(text_anchor: documentai.Document.TextAnchor, text: str) -> str:\n",
    "        \"\"\"Extract text from the document based on a text anchor.\"\"\"\n",
    "        if not text_anchor.text_segments:\n",
    "            return \"\"\n",
    "        start_index = int(text_anchor.text_segments[0].start_index)\n",
    "        end_index = int(text_anchor.text_segments[-1].end_index)\n",
    "        return text[start_index:end_index].strip()\n",
    "\n",
    "    # 4. Extract key/value pairs from all pages\n",
    "    form_data = []\n",
    "    for page in document.pages:\n",
    "        for field in page.form_fields:\n",
    "            field_name = get_text(field.field_name.text_anchor, document.text)\n",
    "            field_value = get_text(field.field_value.text_anchor, document.text)\n",
    "            form_data.append({\"key\": field_name, \"value\": field_value})\n",
    "\n",
    "    print(f\"Found {len(form_data)} key-value pairs.\")\n",
    "\n",
    "    # 5. Use pandas to create a DataFrame\n",
    "    df = pd.DataFrame(form_data)\n",
    "    print(\"DataFrame created:\")\n",
    "    print(df.head())\n",
    "\n",
    "    # 6. Save the DataFrame to a CSV file in Cloud Storage\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(output_bucket)\n",
    "    blob = bucket.blob(output_filename)\n",
    "\n",
    "    # Convert DataFrame to CSV string and upload\n",
    "    csv_data = df.to_csv(index=False)\n",
    "    blob.upload_from_string(csv_data, content_type=\"text/csv\")\n",
    "\n",
    "    print(f\"Successfully saved output to gs://{output_bucket}/{output_filename}\")\n",
    "\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # TODO(developer): Set these variables before running the sample.\n",
    "    project_id = \"qwiklabs-gcp-03-25b8e7edf7ec\"\n",
    "    location = \"us\"  # e.g., \"us\"\n",
    "    processor_id = \"33261d5ae6798457\"\n",
    "    # The GCS bucket provided in the prompt\n",
    "    gcs_bucket = \"qwiklabs-gcp-03-25b8e7edf7ec-cepf-documentai\"\n",
    "    gcs_uri = f\"gs://{gcs_bucket}/sample-intake-form.pdf\"\n",
    "    output_filename = \"cepf_form_parser.csv\"\n",
    "\n",
    "    process_and_extract_form_data(\n",
    "        project_id=project_id,\n",
    "        location=location,\n",
    "        processor_id=processor_id,\n",
    "        gcs_uri=gcs_uri,\n",
    "        output_bucket=gcs_bucket,\n",
    "        output_filename=output_filename,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c3e5ec3-f98d-4c73-ba56-3734a106fcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract table data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9976c888-6a01-426b-a8c3-dcabb7aeaf21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making request to Document AI API...\n",
      "Request complete. Parsing tables...\n",
      "Parsing table 0 on page 1...\n",
      "Successfully saved table 0 to gs://qwiklabs-gcp-03-25b8e7edf7ec-cepf-documentai/sample-form-with-table-tb0.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import io\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import documentai\n",
    "from google.cloud import storage\n",
    "from typing import Sequence\n",
    "\n",
    "\n",
    "def extract_and_save_table_data(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    processor_id: str,\n",
    "    gcs_uri: str,\n",
    "    output_bucket_name: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Processes a document containing tables, extracts the data from each table,\n",
    "    and saves each table as a separate CSV file in a GCS bucket.\n",
    "    \"\"\"\n",
    "    # 1. Instantiate Document AI Client\n",
    "    docai_client = documentai.DocumentProcessorServiceClient(\n",
    "        client_options=ClientOptions(\n",
    "            api_endpoint=f\"{location}-documentai.googleapis.com\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 2. Configure and make the processing request\n",
    "    resource_name = docai_client.processor_path(project_id, location, processor_id)\n",
    "    gcs_document = documentai.GcsDocument(\n",
    "        gcs_uri=gcs_uri, mime_type=\"application/pdf\"\n",
    "    )\n",
    "    request = documentai.ProcessRequest(\n",
    "        name=resource_name, gcs_document=gcs_document\n",
    "    )\n",
    "\n",
    "    print(\"Making request to Document AI API...\")\n",
    "    result = docai_client.process_document(request=request)\n",
    "    document = result.document\n",
    "    print(\"Request complete. Parsing tables...\")\n",
    "\n",
    "    # 3. Define a helper function to get text from the document\n",
    "    def get_text(text_anchor: documentai.Document.TextAnchor, text: str) -> str:\n",
    "        \"\"\"Extract text from the document based on a text anchor.\"\"\"\n",
    "        if not text_anchor.text_segments:\n",
    "            return \"\"\n",
    "        start_index = int(text_anchor.text_segments[0].start_index)\n",
    "        end_index = int(text_anchor.text_segments[-1].end_index)\n",
    "        # Replace newlines and tabs with spaces, and strip leading/trailing whitespace\n",
    "        return text[start_index:end_index].replace(\"\\n\", \" \").replace(\"\\t\", \" \").strip()\n",
    "\n",
    "    # 4. Iterate through pages and tables to extract data\n",
    "    storage_client = storage.Client()\n",
    "    output_bucket = storage_client.bucket(output_bucket_name)\n",
    "\n",
    "    for page_num, page in enumerate(document.pages):\n",
    "        for table_num, table in enumerate(page.tables):\n",
    "            print(f\"Parsing table {table_num} on page {page_num + 1}...\")\n",
    "\n",
    "            # Extract header rows\n",
    "            header_rows = [\n",
    "                [get_text(cell.layout.text_anchor, document.text) for cell in row.cells]\n",
    "                for row in table.header_rows\n",
    "            ]\n",
    "\n",
    "            # Extract body rows\n",
    "            body_rows = [\n",
    "                [get_text(cell.layout.text_anchor, document.text) for cell in row.cells]\n",
    "                for row in table.body_rows\n",
    "            ]\n",
    "            \n",
    "            # Combine all rows\n",
    "            all_rows = header_rows + body_rows\n",
    "\n",
    "            # 5. Create CSV content in memory\n",
    "            csv_output = io.StringIO()\n",
    "            writer = csv.writer(csv_output)\n",
    "            writer.writerows(all_rows)\n",
    "\n",
    "            # 6. Upload the CSV to Cloud Storage\n",
    "            # Per the prompt, the output filename is specific to the first table (tb0).\n",
    "            if table_num == 0:\n",
    "                output_filename = f\"sample-form-with-table-tb{table_num}.csv\"\n",
    "                blob = output_bucket.blob(output_filename)\n",
    "                blob.upload_from_string(\n",
    "                    csv_output.getvalue(), content_type=\"text/csv\"\n",
    "                )\n",
    "                print(\n",
    "                    f\"Successfully saved table {table_num} to gs://{output_bucket_name}/{output_filename}\"\n",
    "                )\n",
    "    \n",
    "    if not document.pages or not document.pages[0].tables:\n",
    "        print(\"No tables found in the document.\")\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # TODO(developer): Set these variables before running the sample.\n",
    "    project_id = \"qwiklabs-gcp-03-25b8e7edf7ec\"\n",
    "    location = \"us\"  # e.g., \"us\"\n",
    "    # It's recommended to use a Form Parser processor for this task.\n",
    "    processor_id = \"33261d5ae6798457\"\n",
    "\n",
    "    # GCS bucket and file as specified in the prompt\n",
    "    gcs_bucket_name = \"qwiklabs-gcp-03-25b8e7edf7ec-cepf-documentai\"\n",
    "    gcs_uri = f\"gs://{gcs_bucket_name}/sample-form-with-table.pdf\"\n",
    "\n",
    "    extract_and_save_table_data(\n",
    "        project_id=project_id,\n",
    "        location=location,\n",
    "        processor_id=processor_id,\n",
    "        gcs_uri=gcs_uri,\n",
    "        output_bucket_name=gcs_bucket_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a13137a-c911-4352-ac3a-95554b4e8edd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m137",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m137"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
